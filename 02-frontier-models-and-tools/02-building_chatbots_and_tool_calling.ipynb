{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a505e1b",
   "metadata": {},
   "source": [
    "## Introduction to Conversational AI Development\n",
    "\n",
    "The journey into building production-ready AI systems takes a significant leap forward when you move beyond simple API calls to creating sophisticated conversational interfaces. This chapter explores the essential techniques for building AI assistants that can maintain context, leverage external tools, and provide genuine business value through natural language interactions.\n",
    "\n",
    "At this stage in your learning journey, you've already mastered the fundamentals of working with frontier language models through their APIs. Now comes the exciting part: transforming those API calls into interactive applications that users can genuinely engage with. We'll explore how to create chat interfaces, manage conversation history, implement tool calling, and build assistants with specialized knowledge and capabilities.\n",
    "\n",
    "## Understanding AI Assistants and Their Core Components\n",
    "\n",
    "An AI assistant represents one of the most common and valuable applications of large language models in commercial settings. The power of these assistants comes from three fundamental capabilities that work in harmony.\n",
    "\n",
    "First, an AI assistant can embody a specific persona that aligns with your brand identity or corporate culture. Through carefully crafted system prompts, you establish the tone, style, and approach the assistant will take in every interaction. This isn't just about being friendly or professional—it's about creating a consistent experience that reflects your organization's values and communication style.\n",
    "\n",
    "Second, successful AI assistants create what we might call an \"illusion of memory.\" While the model itself doesn't truly remember past conversations in the way humans do, we can architect our applications to maintain conversational context. By carefully managing the conversation history and including it in each API call, we enable the assistant to understand what has been discussed and respond appropriately to follow-up questions or references to earlier parts of the dialogue.\n",
    "\n",
    "Third, expertise makes an assistant genuinely valuable. Through strategic prompt engineering and information injection, you can equip your assistant with domain-specific knowledge. This transforms a general-purpose language model into a specialized tool that understands your business, your products, and your customers' needs.\n",
    "\n",
    "## The Art of Prompt Engineering for Assistants\n",
    "\n",
    "Thoughtful prompt construction forms the foundation of effective AI assistants. System prompts serve as the ground rules and context-setting mechanism for your assistant's behavior. One of the most critical patterns in prompt engineering is the instruction: \"If you don't know the answer, just say so.\" This simple directive helps combat hallucination—the tendency of language models to generate plausible-sounding but incorrect information when they lack actual knowledge of a topic.\n",
    "\n",
    "Beyond preventing hallucinations, system prompts provide essential background information. You might include details about your company, your products, current promotions, or relevant policies. This background forms the knowledge base from which your assistant draws when responding to queries.\n",
    "\n",
    "Multi-shot prompting represents a powerful technique for shaping model behavior. By inserting concrete examples into the system prompt—typically formatted as \"if you get this question, this is how you should answer\"—you bias the model's predictions. Remember that language models work by predicting the most likely next token based on the input they receive. When you provide examples in the system prompt, you're essentially teaching the model what \"likely\" looks like in your specific context. As the model processes these examples, it becomes more probable that its responses will align with the patterns you've demonstrated.\n",
    "\n",
    "### Understanding Callback Functions\n",
    "\n",
    "The heart of your chat interface (gradio) lies in the callback function. **A callback is simply a function you provide to Gradio, which Gradio will invoke whenever a user submits a message**. This function follows a specific signature: it accepts two parameters and returns a response.\n",
    "\n",
    "The first parameter, conventionally called `message`, contains the text the user just typed into the chat interface. The second parameter, `history`, contains the entire conversation that has occurred up to this point. Gradio handles the user interface rendering—displaying the conversation thread and providing an input field—and your callback function determines how the system responds to each new message.\n",
    "\n",
    "Initially, you might create an extremely simple callback that always returns the same response, perhaps \"bananas\" as a playful example. This demonstrates the fundamental pattern: Gradio displays the UI, captures user input, calls your function with the current message and conversation history, and displays whatever your function returns. This one-way conversation pattern helps you understand the flow before adding complexity.\n",
    "\n",
    "When you connect this callback to Gradio using `gr.Interface`, specifying `type=\"messages\"`, you're telling Gradio to format the conversation history using the OpenAI messages format. This proves incredibly convenient because most developers use these chat interfaces specifically to call language model APIs, and having the data pre-formatted saves significant effort.\n",
    "\n",
    "### Examining the Messages Format\n",
    "\n",
    "The messages format that Gradio provides deserves careful examination. When your callback function receives the `history` parameter, it arrives as a list of dictionaries. Each dictionary contains a `role` field (typically \"user\" or \"assistant\") and a `content` field with the actual message text. You might also see additional metadata fields.\n",
    "\n",
    "This format mirrors OpenAI's API structure almost exactly, which is intentional. However, some language model providers—particularly Gemini and Grok—reject messages that contain extra fields like metadata. To ensure compatibility across different model providers, you can clean the history by creating a new list that includes only the `role` and `content` fields, stripping out anything extra.\n",
    "\n",
    "## Implementing Real Language Model Integration\n",
    "\n",
    "Once you understand the callback pattern, integrating an actual language model becomes straightforward. Your callback function needs to construct the complete messages array that you'll send to the API.\n",
    "\n",
    "This array begins with a system message. Remember, Gradio only passes you the visible conversation history from the UI—it doesn't know about your system prompt. You must explicitly prepend a message with `role: \"system\"` and your system message content.\n",
    "\n",
    "Next, you include all the conversation history that Gradio provided. Finally, you append the current user message. This gives you a complete messages array: system context first, then the back-and-forth conversation history, and finally the user's latest input.\n",
    "\n",
    "With this messages array prepared, you call the language model API exactly as you've done before, passing in your chosen model and the messages array. The response comes back in the familiar format, and you extract the content from `response.choices[0].message.content` and return it from your callback function.\n",
    "\n",
    "When Gradio receives this return value, it automatically displays it in the chat interface. The user sees their message, followed by the assistant's response, all rendered in an attractive, familiar chat interface format.\n",
    "\n",
    "### Adding Streaming for Better User Experience\n",
    "\n",
    "Streaming responses significantly improve the user experience by showing text as it generates rather than waiting for the complete response. Implementing streaming in your callback requires only minor modifications.\n",
    "\n",
    "You add `stream=True` to your API call parameters. The API then returns a stream object that you can iterate over using a for loop. For each chunk that arrives, you accumulate the text in a response variable. The key change is using `yield` instead of `return`. This transforms your callback function into a generator—a special Python construct that can return multiple values over time.\n",
    "\n",
    "## Advanced Prompting Techniques\n",
    "\n",
    "The system prompt represents your most powerful tool for customizing assistant behavior. Consider an example where you're building an assistant for a clothing store. Your system prompt might establish the context: \"You are a helpful assistant in a clothes store.\" But it can go much further.\n",
    "\n",
    "You might include specific business rules: \"You should try to gently encourage the customer to try items that are on sale. Hats are 60% off and most other items are 50% off.\" This gives your assistant commercial knowledge and a soft sales objective.\n",
    "\n",
    "One-shot prompting takes this further by providing an example interaction: \"For example, if the customer says, 'I'm looking to buy a hat,' you could reply with something like, 'Wonderful! We have lots of hats, including several that are part of our sales event.'\" This example demonstrates the tone, enthusiasm level, and information-sharing approach you want the assistant to adopt.\n",
    "\n",
    "You can also add specific handling instructions: \"If the customer asks for shoes, you should respond that shoes are not on sale today, but remind the customer to look for hats.\" As you add more such examples, you're practicing multi-shot prompting—providing multiple scenarios and desired responses that guide the model's behavior across various situations.\n",
    "\n",
    "### Dynamic Context Injection\n",
    "\n",
    "The real power emerges when you dynamically modify the system prompt based on the user's input. Imagine detecting that the user mentioned \"belt\" in their message. You could programmatically add a new section to your system prompt: \"The store does not sell belts. If you are asked for belts, be sure to point out other items on sale.\"\n",
    "\n",
    "While this specific example might seem trivial—why not always include this information?—it demonstrates a crucial concept. In a real store with thousands of products, including every possible piece of information in every system prompt would be impractical. Your prompts would become enormous, degrading model accuracy while consuming unnecessary tokens and increasing costs.\n",
    "\n",
    "This dynamic context injection represents your first glimpse into Retrieval-Augmented Generation (RAG). The core idea is elegantly simple: intelligently select relevant information and insert it into the prompt at inference time. This equips the model with the specific knowledge it needs to answer the current query without overwhelming it with irrelevant details.\n",
    "\n",
    "RAG isn't a complex algorithmic innovation—it's a practical approach to prompt enhancement. The sophistication comes from determining what information is truly relevant for each query, rather than using crude keyword matching. As you progress in your AI development journey, you'll learn increasingly sophisticated techniques for selecting and injecting the right context at the right time.\n",
    "\n",
    "## Understanding Tool Calling Architecture\n",
    "\n",
    "Tool calling often sounds mysterious or complex when you first encounter it, but the underlying mechanism is remarkably straightforward. Let's dispel any confusion by examining exactly what happens when a language model \"uses tools.\"\n",
    "\n",
    "Language models are, fundamentally, statistical programs that predict the next most likely token based on their training and the input they receive. They're neural networks running on remote servers, processing inputs and generating outputs. They don't magically reach across the internet to execute code on your local machine or directly interact with databases and APIs.\n",
    "\n",
    "Here's the reality: when you enable tool calling, you're following a specific communication protocol with the language model. You describe available tools in your initial prompt using a structured JSON format. The language model has been trained to recognize this format and can respond by indicating it wants to use one of these tools.\n",
    "\n",
    "When the model decides a tool would be helpful, it doesn't execute anything itself. Instead, it generates tokens that represent a request to call a specific tool with specific parameters. Your code receives this response, detects that it's a tool call request rather than a regular text response, executes the appropriate function locally, and then makes a second API call to the language model.\n",
    "\n",
    "This second call includes the entire conversation history: the user's original question, the model's request to use a tool, and the result your code obtained from executing that tool. Based on this expanded context, the model generates a final response that incorporates the tool's output.\n",
    "\n",
    "### The Tool Calling Workflow\n",
    "\n",
    "Let's walk through a concrete example. Imagine you're building an airline assistant that can look up ticket prices. You write a Python function that queries your database for pricing information. You then describe this function to the language model using a specific JSON schema that specifies the function name, its purpose, what parameters it accepts, and what each parameter means.\n",
    "\n",
    "When a user asks \"How much is a flight to Paris?\", you include your tool description in the API call. The model recognizes that answering this question requires information it doesn't have, and it sees a tool that can provide that information. It responds with something like: \"Please use the get_ticket_price tool with destination_city='Paris'.\"\n",
    "\n",
    "Your code detects this response type, extracts the function name and parameters, calls your actual Python function, and receives a result—perhaps \"$850.\" You then construct a new messages array that includes: the original user question, the model's tool call request, and the result from executing the tool (formatted as a message with `role: \"tool\"`). You send this complete history back to the API.\n",
    "\n",
    "The model now has all the information it needs. It sees the user asked about Paris flights, it \"remembers\" requesting pricing information (through the conversation history), and it has the actual price. It generates a helpful response: \"A return ticket to Paris costs $850. Would you like to book this flight?\"\n",
    "\n",
    "### The JSON Schema for Tool Descriptions\n",
    "\n",
    "Tools must be described using a specific JSON format. While this format can feel verbose and tedious to write, it's essential for enabling the language model to understand what tools are available and how to use them.\n",
    "\n",
    "A tool description includes several key elements:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a2bad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'get_ticket_price',\n",
       "  'description': 'Get the price of a return ticket to the destination city',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'destination_city': {'type': 'string',\n",
       "     'description': 'The city that the customer wants to travel to'}},\n",
       "   'required': ['destination_city']}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_ticket_price\",\n",
    "        \"description\": \"Get the price of a return ticket to the destination city\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"destination_city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city that the customer wants to travel to\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"destination_city\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d2c32",
   "metadata": {},
   "source": [
    "The `name` identifies the function. The `description` explains what the function does—this is crucial because the model uses this description to decide when the tool is appropriate. The `parameters` section describes each argument using JSON Schema syntax, including the data type and a description of what that parameter represents.\n",
    "\n",
    "Language models have been trained on extensive examples of this format, so they understand how to interpret these schemas and generate properly formatted tool call requests.\n",
    "\n",
    "## Implementing Tool Calling in Practice\n",
    "\n",
    "Implementing tool calling requires modifications to your chat callback function. First, you need to pass the tool descriptions to the API when you make your initial call. This typically involves adding a `tools` parameter that contains your JSON-formatted tool descriptions.\n",
    "\n",
    "Second, you must examine the response to determine whether it's a regular text response or a tool call request. The response object includes a `finish_reason` field. When this field equals \"tool_calls\", you know the model wants to use a tool rather than directly answering the user.\n",
    "\n",
    "When you detect a tool call request, you need to:\n",
    "\n",
    "1. Extract the tool call details from the response\n",
    "2. Identify which function was requested\n",
    "3. Extract the parameters for that function\n",
    "4. Execute your actual Python function with those parameters\n",
    "5. Construct a new message with `role: \"tool\"` containing the function's result\n",
    "6. Make a second API call with the expanded conversation history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28c942af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f49654",
   "metadata": {},
   "source": [
    "Following `FLIGHT_DB` dictionary represents a structured in-memory database for the FlightAI airline, organizing flight information by destination city. Each city entry contains shared metadata such as the operating airline and currency, along with a nested `flights` object that lists all available cabin classes for that route. For each class (e.g., economy, premium economy, business, first class), the database stores key commercial and operational details including ticket price, flight duration, baggage allowance, refund eligibility, and real-time seat availability. This hierarchical design makes it easy to query flights by city, compare classes within the same route, select the cheapest or most suitable option, and support booking logic while remaining extensible for future additions such as taxes, layovers, or fare rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95d66db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLIGHT_DB = {\n",
    "    \"london\": {\n",
    "        \"currency\": \"USD\",\n",
    "        \"airline\": \"FlightAI\",\n",
    "        \"flights\": {\n",
    "            \"economy\": {\n",
    "                \"price\": 799,\n",
    "                \"duration_hours\": 7,\n",
    "                \"baggage_kg\": 23,\n",
    "                \"refundable\": False,\n",
    "                \"seats_available\": 42\n",
    "            },\n",
    "            \"premium_economy\": {\n",
    "                \"price\": 1099,\n",
    "                \"duration_hours\": 7,\n",
    "                \"baggage_kg\": 28,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 18\n",
    "            },\n",
    "            \"business\": {\n",
    "                \"price\": 1899,\n",
    "                \"duration_hours\": 6.5,\n",
    "                \"baggage_kg\": 32,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 6\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"paris\": {\n",
    "        \"currency\": \"USD\",\n",
    "        \"airline\": \"FlightAI\",\n",
    "        \"flights\": {\n",
    "            \"economy\": {\n",
    "                \"price\": 899,\n",
    "                \"duration_hours\": 8,\n",
    "                \"baggage_kg\": 23,\n",
    "                \"refundable\": False,\n",
    "                \"seats_available\": 35\n",
    "            },\n",
    "            \"premium_economy\": {\n",
    "                \"price\": 1199,\n",
    "                \"duration_hours\": 7.8,\n",
    "                \"baggage_kg\": 28,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 14\n",
    "            },\n",
    "            \"business\": {\n",
    "                \"price\": 1999,\n",
    "                \"duration_hours\": 7.5,\n",
    "                \"baggage_kg\": 32,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 5\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"tokyo\": {\n",
    "        \"currency\": \"USD\",\n",
    "        \"airline\": \"FlightAI\",\n",
    "        \"flights\": {\n",
    "            \"economy\": {\n",
    "                \"price\": 1400,\n",
    "                \"duration_hours\": 14,\n",
    "                \"baggage_kg\": 23,\n",
    "                \"refundable\": False,\n",
    "                \"seats_available\": 50\n",
    "            },\n",
    "            \"premium_economy\": {\n",
    "                \"price\": 1850,\n",
    "                \"duration_hours\": 13.5,\n",
    "                \"baggage_kg\": 28,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 20\n",
    "            },\n",
    "            \"business\": {\n",
    "                \"price\": 3200,\n",
    "                \"duration_hours\": 13,\n",
    "                \"baggage_kg\": 32,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 8\n",
    "            },\n",
    "            \"first_class\": {\n",
    "                \"price\": 5200,\n",
    "                \"duration_hours\": 12.8,\n",
    "                \"baggage_kg\": 40,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 2\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"berlin\": {\n",
    "        \"currency\": \"USD\",\n",
    "        \"airline\": \"FlightAI\",\n",
    "        \"flights\": {\n",
    "            \"economy\": {\n",
    "                \"price\": 499,\n",
    "                \"duration_hours\": 6,\n",
    "                \"baggage_kg\": 23,\n",
    "                \"refundable\": False,\n",
    "                \"seats_available\": 60\n",
    "            },\n",
    "            \"business\": {\n",
    "                \"price\": 1299,\n",
    "                \"duration_hours\": 5.7,\n",
    "                \"baggage_kg\": 32,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 10\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"new york\": {\n",
    "        \"currency\": \"USD\",\n",
    "        \"airline\": \"FlightAI\",\n",
    "        \"flights\": {\n",
    "            \"economy\": {\n",
    "                \"price\": 650,\n",
    "                \"duration_hours\": 5,\n",
    "                \"baggage_kg\": 23,\n",
    "                \"refundable\": False,\n",
    "                \"seats_available\": 48\n",
    "            },\n",
    "            \"premium_economy\": {\n",
    "                \"price\": 980,\n",
    "                \"duration_hours\": 4.8,\n",
    "                \"baggage_kg\": 28,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 22\n",
    "            },\n",
    "            \"business\": {\n",
    "                \"price\": 1750,\n",
    "                \"duration_hours\": 4.5,\n",
    "                \"baggage_kg\": 32,\n",
    "                \"refundable\": True,\n",
    "                \"seats_available\": 9\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c92af4",
   "metadata": {},
   "source": [
    "The `lookup_flight` function serves as a backend tool that allows querying the `FLIGHT_DB` for flight information based on a specified destination. It first normalizes the city name to lowercase for consistent lookups and checks if the destination exists in the database. If the city is not found, it returns a structured message indicating unavailability. When a specific cabin class is provided, the function attempts to locate that class within the available flights. If the class exists, it returns detailed information including price, currency, flight duration, baggage allowance, refund eligibility, and available seats. If the class is not offered, it provides a clear reason for its unavailability, ensuring the system handles edge cases gracefully.\n",
    "\n",
    "For general queries without a specified class, the function sorts all available cabin classes by price and either returns a limited number of tickets (based on the `limit` parameter) or all options if `show_all` is set to `True`. The returned data is structured in a consistent format, with each ticket entry containing essential details such as class, price, duration, baggage, refund policy, and seats available. This design allows the AI assistant to present concise, accurate, and user-friendly information, whether the user requests a single class or a comparison of multiple ticket options. By keeping all computations deterministic and relying directly on the database, the function ensures that responses are reliable and never invented by the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2323f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backend Function (Tool)\n",
    "\n",
    "def lookup_flight(\n",
    "    destination_city: str,\n",
    "    cabin_class: str | None = None,\n",
    "    show_all: bool = False,\n",
    "    limit: int = 3\n",
    "):\n",
    "    city = destination_city.lower()\n",
    "    city_data = FLIGHT_DB.get(city)\n",
    "\n",
    "    if not city_data:\n",
    "        return {\n",
    "            \"destination\": city,\n",
    "            \"available\": False,\n",
    "            \"reason\": \"Destination not found\"\n",
    "        }\n",
    "\n",
    "    flights = city_data[\"flights\"]\n",
    "\n",
    "    # Normalize class name if provided\n",
    "    if cabin_class:\n",
    "        cabin_class = cabin_class.lower()\n",
    "        data = flights.get(cabin_class)\n",
    "\n",
    "        if not data:\n",
    "            return {\n",
    "                \"destination\": city,\n",
    "                \"available\": False,\n",
    "                \"reason\": f\"{cabin_class} class not available\"\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"destination\": city,\n",
    "            \"class\": cabin_class,\n",
    "            \"price\": data[\"price\"],\n",
    "            \"currency\": city_data[\"currency\"],\n",
    "            \"duration_hours\": data[\"duration_hours\"],\n",
    "            \"baggage_kg\": data[\"baggage_kg\"],\n",
    "            \"refundable\": data[\"refundable\"],\n",
    "            \"seats_available\": data[\"seats_available\"]\n",
    "        }\n",
    "\n",
    "    # Sort all tickets by price\n",
    "    sorted_flights = sorted(\n",
    "        flights.items(),\n",
    "        key=lambda item: item[1][\"price\"]\n",
    "    )\n",
    "\n",
    "    # Show all or limited number\n",
    "    selected_flights = (\n",
    "        sorted_flights if show_all else sorted_flights[:limit]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"destination\": city,\n",
    "        \"currency\": city_data[\"currency\"],\n",
    "        \"tickets\": [\n",
    "            {\n",
    "                \"class\": cls,\n",
    "                \"price\": data[\"price\"],\n",
    "                \"duration_hours\": data[\"duration_hours\"],\n",
    "                \"baggage_kg\": data[\"baggage_kg\"],\n",
    "                \"refundable\": data[\"refundable\"],\n",
    "                \"seats_available\": data[\"seats_available\"]\n",
    "            }\n",
    "            for cls, data in selected_flights\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7461c291",
   "metadata": {},
   "source": [
    "The `flight_lookup_tool` dictionary defines a **tool schema** that an AI assistant can use to query flight information from the backend in a structured and predictable way. This schema informs the model about the tool's purpose, the input parameters it requires, and how to interpret the outputs, enabling the AI to call it reliably when responding to user queries.\n",
    "\n",
    "- `\"name\": \"lookup_flight\"` specifies the unique identifier of the tool. The AI uses this name internally to trigger the flight lookup functionality.\n",
    "- `\"description\"` provides a short explanation of the tool's purpose. It instructs the assistant to retrieve airline ticket information and explains that setting `show_all=true` allows the customer to view all available ticket classes, not just the default selection.\n",
    "- `\"parameters\"` defines the expected input using JSON schema:\n",
    "  - `\"destination_city\"` (string) is required and specifies the city the customer wants to travel to.\n",
    "  - `\"show_all\"` (boolean) is optional and indicates whether the assistant should display all available ticket classes or only a subset.\n",
    "- `\"required\": [\"destination_city\"]` ensures that at least the destination city must be provided for the tool to function properly.\n",
    "- `\"additionalProperties\": False` prevents extra, unspecified fields from being passed, enforcing strict input validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f695e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Schema (Function Definition for LLM)\n",
    "\n",
    "flight_lookup_tool = {\n",
    "    \"name\": \"lookup_flight\",\n",
    "    \"description\": (\n",
    "        \"Retrieve airline ticket information. \"\n",
    "        \"Use show_all=true when the customer asks to see more options or all ticket classes.\"\n",
    "    ),\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"City the customer wants to travel to\"\n",
    "            },\n",
    "            \"show_all\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"Set true if the customer wants to see all available ticket classes\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": flight_lookup_tool}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18574551",
   "metadata": {},
   "source": [
    "The `booking_tool` dictionary below defines a **tool schema** that an AI assistant can use to handle flight bookings in a structured and deterministic way. This tool essentially tells the model what kind of action it can perform, what input it expects, and what parameters are required to execute the booking.\n",
    "\n",
    "- `\"name\": \"book_flight\"` specifies the identifier of the tool. This is the name the AI assistant will reference when it wants to call this functionality.\n",
    "- `\"description\"` provides a short explanation of what the tool does, which in this case is to book a flight after collecting the passenger's **name** and **email**. This helps the model understand the purpose of the tool and when it should be invoked.\n",
    "- `\"parameters\"` defines the expected input schema using JSON schema notation. It specifies that the tool expects an object containing the following properties:\n",
    "  - `\"name\"`: a string representing the passenger’s full name.\n",
    "  - `\"email\"`: a string representing the passenger’s email address.\n",
    "  - `\"destination_city\"`: a string for the city the passenger wants to travel to.\n",
    "  - `\"cabin_class\"`: a string indicating the desired flight class (e.g., economy, business, first).\n",
    "- `\"required\"` lists the parameters that must always be provided for the tool to function correctly. In this case, all four fields—`name`, `email`, `destination_city`, and `cabin_class`—are mandatory, ensuring that the AI assistant cannot attempt a booking without complete information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc32bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_tool = {\n",
    "    \"name\": \"book_flight\",\n",
    "    \"description\": \"Book a flight after collecting name and email\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\"type\": \"string\"},\n",
    "            \"email\": {\"type\": \"string\"},\n",
    "            \"destination_city\": {\"type\": \"string\"},\n",
    "            \"cabin_class\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"name\", \"email\", \"destination_city\", \"cabin_class\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOKINGS_DB = []\n",
    "BOOKINGS_FILE = \"bookings.json\"\n",
    "\n",
    "def book_flight(\n",
    "    name: str,\n",
    "    email: str,\n",
    "    destination_city: str,\n",
    "    cabin_class: str\n",
    "):\n",
    "    global BOOKINGS_DB\n",
    "    \n",
    "    city = destination_city.lower()\n",
    "    cabin_class = cabin_class.lower()\n",
    "\n",
    "    city_data = FLIGHT_DB.get(city)\n",
    "    if not city_data:\n",
    "        return {\"success\": False, \"reason\": \"Destination not available\"}\n",
    "\n",
    "    flight = city_data[\"flights\"].get(cabin_class)\n",
    "    if not flight:\n",
    "        return {\"success\": False, \"reason\": \"Class not available\"}\n",
    "\n",
    "    if flight[\"seats_available\"] <= 0:\n",
    "        return {\"success\": False, \"reason\": \"No seats available\"}\n",
    "\n",
    "    # Reserve seat\n",
    "    flight[\"seats_available\"] -= 1\n",
    "\n",
    "    booking = {\n",
    "        \"booking_id\": str(uuid.uuid4()),\n",
    "        \"name\": name,\n",
    "        \"email\": email,\n",
    "        \"destination\": city,\n",
    "        \"class\": cabin_class,\n",
    "        \"price\": flight[\"price\"],\n",
    "        \"currency\": city_data[\"currency\"],\n",
    "        \"timestamp\": datetime.utcnow().isoformat()\n",
    "    }\n",
    "   \n",
    "    BOOKINGS_DB.append(booking)\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"booking_id\": booking[\"booking_id\"],\n",
    "        \"destination\": city,\n",
    "        \"class\": cabin_class,\n",
    "        \"price\": flight[\"price\"],\n",
    "        \"currency\": city_data[\"currency\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bec73d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Call Handler\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    result = lookup_flight(args[\"destination_city\"])\n",
    "\n",
    "    tool_response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"content\": json.dumps(result)\n",
    "    }\n",
    "\n",
    "    return tool_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ae23eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming Chat Function (Gradio-Compatible)\n",
    "\n",
    "client = OpenAI()\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "\n",
    "def chat(message, history, tools):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    messages += history\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    # First request (may trigger tool)\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    choice = response.choices[0]\n",
    "\n",
    "    # Tool call path\n",
    "    if choice.finish_reason == \"tool_calls\":\n",
    "        messages.append(choice.message)\n",
    "        tool_message = handle_tool_call(choice.message)\n",
    "        messages.append(tool_message)\n",
    "\n",
    "        # Second request (final answer, streamed)\n",
    "        stream = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        full_text = \"\"\n",
    "        for chunk in stream:\n",
    "            delta = chunk.choices[0].delta\n",
    "            if delta and delta.content:\n",
    "                full_text += delta.content\n",
    "                yield full_text\n",
    "\n",
    "    else:\n",
    "        yield choice.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d87a116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": booking_tool\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1c8b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Message (Steering)\n",
    "\n",
    "system_message = (\n",
    "    \"You are FlightAI, a professional airline assistant. \"\n",
    "    \"Only book a flight after the customer explicitly confirms \"\n",
    "    \"their full name, email address, destination, and cabin class. \"\n",
    "    \"If any of these are missing, ask for them. \"\n",
    "    \"Never guess personal information.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a49d67c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7877\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/helpers.py:968: UserWarning: Unexpected argument. Filling with None.\n",
      "  warnings.warn(\"Unexpected argument. Filling with None.\")\n"
     ]
    }
   ],
   "source": [
    "# Gradio UI\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    type=\"messages\",\n",
    "    title=\"✈️ FlightAI – Airline Assistant\",\n",
    "    description=\"Ask about ticket prices, destinations, and flight details.\"\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
