{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d540b4e",
   "metadata": {},
   "source": [
    "# Welcome to LLM Engineering\n",
    "\n",
    "This tutorial takes a hands-on approach from the very beginning. Instead of spending time on lengthy introductions about what we'll cover, we're going to jump straight into experimentation. The best way to understand Large Language Models is to start using them immediately and build your knowledge through direct experience.\n",
    "\n",
    "If you've used ChatGPT, Claude, or similar AI assistants, you're already familiar with interacting with language models. However, those systems run on remote servers controlled by their respective companies. What we're about to explore is fundamentally different: running AI models directly on your own computer. This gives you complete control over the technology, eliminates dependency on internet connectivity, and provides deeper insight into how these systems actually function.\n",
    "\n",
    "## Running Your First Local LLM\n",
    "\n",
    "The tool we'll use is called `Ollama`, which makes it remarkably simple to download and run open-source language models on your machine. Ollama works identically across Windows, macOS, and Linux, so regardless of your operating system, you'll have access to the same capabilities.\n",
    "\n",
    "Start by visiting the Ollama website and downloading the appropriate version for your system. The installation process follows standard conventions for your operating system. On macOS, you'll drag the application to your Applications folder. On Windows, you'll run through a typical installation wizard. Once installed, launch Ollama. You'll see a graphical interface, but we won't be using it. Instead, close that window because we're going to interact with Ollama through the command line.\n",
    "\n",
    "The command line provides direct access to your computer's capabilities without the overhead of graphical interfaces. On macOS, open Terminal from Applications > Utilities. On Windows, open PowerShell from the Start menu. Linux users will use their preferred terminal application.\n",
    "\n",
    "Once your terminal is open, type `ollama` and press Enter. You should see a help screen showing available commands. If you see this, Ollama is installed correctly. Type `ollama serve` and you should see a message indicating the address is already in use, confirming that Ollama is running.\n",
    "\n",
    "## Downloading and Running Models\n",
    "\n",
    "Now we'll actually run a language model. The command structure is straightforward: `ollama run` followed by the model name. We'll start with Gemma, an open-source model from Google. Type the following command:\n",
    "\n",
    "```\n",
    "ollama run gemma2:270m\n",
    "```\n",
    "\n",
    "The \"270m\" refers to 270 million parameters, which are the internal values the model learned during training. While this sounds like a large number, it's actually quite small compared to most production models that contain billions of parameters. This smaller size means faster downloads and lower hardware requirements, making it perfect for initial experimentation.\n",
    "\n",
    "When you press Enter, Ollama downloads the model from the internet. Depending on your connection speed, this might take anywhere from a few seconds to a couple of minutes. Once complete, you'll see a prompt cursor indicating the model is ready for input.\n",
    "\n",
    "Try typing a simple greeting like \"Hi there\" and observe the response. The model will engage conversationally, demonstrating its language understanding capabilities. Keep in mind that this is a very small model, so while it can handle basic conversations, it won't match the sophistication of larger commercial systems.\n",
    "\n",
    "To exit your conversation, press Ctrl+D. Note that on macOS, this is the Control key, not Command.\n",
    "\n",
    "## Exploring Different Model Sizes\n",
    "\n",
    "Ollama provides access to numerous open-source models of varying sizes and capabilities. Visit the Ollama website and click on the Models section to browse what's available. You'll find models from different organizations, each offered in multiple size variants.\n",
    "\n",
    "Let's try a larger model to see how size affects capability. Microsoft's Phi-3 is a good next step. Type:\n",
    "\n",
    "```\n",
    "ollama run phi3\n",
    "```\n",
    "\n",
    "The first download will take longer due to the increased size, approximately 2.2GB. However, once downloaded, the model remains cached locally, so subsequent uses launch instantly. After it loads, try asking for a fun fact or engaging in a more complex conversation. The improvement in response quality compared to the smaller Gemma model will be immediately noticeable.\n",
    "\n",
    "For those with more powerful hardware, specifically machines with at least 16GB of RAM and around 20GB of free storage, you can experiment with even more capable models. The GPT-4o model represents OpenAI's contribution to the open-source ecosystem and offers performance approaching commercial-grade assistants:\n",
    "\n",
    "```\n",
    "ollama run gpt4o\n",
    "```\n",
    "\n",
    "This download will be substantial and may take several minutes depending on your internet speed. Once loaded, you can give it practical tasks. For example, you might say: \"Hi, I'm trying to learn Spanish. I'm a total beginner. Please have a conversation with me as my Spanish tutor.\"\n",
    "\n",
    "The model's response will likely surprise you. It may display its reasoning process before providing its final response, giving you transparency into how it approaches problems. The conversation that follows will resemble what you'd find in a commercial language learning application, demonstrating that locally-run models can provide genuine value for real-world tasks.\n",
    "\n",
    "## Understanding What You've Accomplished\n",
    "\n",
    "What you've just experienced represents a significant shift in how AI technology can be accessed and used. The models you've downloaded are the result of enormous computational effort and sophisticated training processes, yet they're freely available for anyone to use, modify, and learn from. This is the foundation upon which you'll build increasingly sophisticated applications.\n",
    "\n",
    "Take time to experiment with different models. Try various sizes to understand the tradeoff between capability and resource requirements. Explore different types of tasks to see where each model excels or struggles. This hands-on exploration builds intuition that will inform every decision you make as you develop LLM-based applications.\n",
    "\n",
    "## Preparing Your Development Environment\n",
    "\n",
    "Before we can build more complex applications, we need to establish a proper development environment. This setup process is often the most challenging part of learning to code, but it's essential. The tools you configure now will serve you throughout this course and in your future work with LLMs.\n",
    "\n",
    "The setup involves five main steps. The first step differs slightly between Windows and macOS users, but after that, everyone follows the same path. This universal approach is made possible by modern tools that abstract away platform differences.\n",
    "\n",
    "Here's what we'll accomplish:\n",
    "\n",
    "1. Clone the course repository from GitHub to create a local copy of all materials\n",
    "2. Install UV, a Python environment manager that ensures everyone has identical package versions\n",
    "3. Create an OpenAI API key for accessing frontier models (with free alternatives available)\n",
    "4. Configure your environment file with the API key\n",
    "5. Verify that everything works correctly\n",
    "\n",
    "Most people complete this setup smoothly within minutes. However, technical environments are complex, and occasionally issues arise. When they do, extensive troubleshooting documentation is available in the course repository.\n",
    "\n",
    "## Git and GitHub Fundamentals\n",
    "\n",
    "Git and GitHub are often confused, but they serve different purposes. Git is version control software that runs on your local computer and tracks changes to your code over time. This allows you to experiment freely, knowing you can always return to a previous working state.\n",
    "\n",
    "GitHub is a cloud-based platform that hosts Git repositories, providing a central location where code can be stored, shared, and collaborated upon. When you clone a repository from GitHub, you create a local copy of that code on your computer. This copy remains connected to the GitHub repository, allowing you to receive updates as the course materials evolve.\n",
    "\n",
    "## Working with the Command Line\n",
    "\n",
    "The command line might seem intimidating if you're new to programming, but it's actually a straightforward tool once you understand the basics. Instead of clicking through graphical menus, you type commands as text. This directness provides precision and power that graphical interfaces cannot match.\n",
    "\n",
    "Your computer's file system is organized into directories (folders) and files. At any given moment, your command line session is located in a particular directory called your current working directory. Basic commands allow you to navigate this structure. The `cd` command changes directories, while `ls` (or `dir` on Windows) lists the contents of your current location. The `mkdir` command creates new directories.\n",
    "\n",
    "On Windows, PowerShell provides these capabilities along with powerful scripting features. On macOS and Linux, Terminal provides access to a Unix-style environment. While specific commands occasionally differ between platforms, the core concepts remain identical.\n",
    "\n",
    "## Installing Git\n",
    "\n",
    "Open your command line interface. Type `git` and press Enter. If you see a help screen describing Git's capabilities, you're ready to proceed. If you see an error indicating Git isn't found, you need to install it.\n",
    "\n",
    "For Windows users, download Git from the official Git website and run the installer with default settings. For macOS users, running any Git command typically triggers an automatic installation prompt for Apple's command line developer tools, which include Git. Linux users can install Git through their distribution's package manager.\n",
    "\n",
    "Once Git is installed and verified, create a projects directory in your home folder. This organizational step becomes increasingly important as you work on multiple projects:\n",
    "\n",
    "```\n",
    "mkdir projects\n",
    "cd projects\n",
    "```\n",
    "\n",
    "Now you're ready to clone the course repository. Navigate to the course GitHub page and locate the green \"Code\" button. Click it and ensure HTTPS is selected, then copy the URL to your clipboard. Back in your command line, type:\n",
    "\n",
    "```\n",
    "git clone [paste the URL here]\n",
    "```\n",
    "\n",
    "Git will download the entire repository, creating a new directory within your projects folder.\n",
    "\n",
    "## Setting Up Your Code Editor\n",
    "\n",
    "An Integrated Development Environment (IDE) is your primary tool for writing and managing code. While you could write code in any text editor, IDEs provide features specifically designed for programmers: syntax highlighting, code completion, debugging tools, and integrated terminal access.\n",
    "\n",
    "Cursor is recommended for this course because it's built on VS Code, the most popular code editor among developers, but adds AI-powered features that can accelerate your learning. However, VS Code itself works perfectly well, as would other popular IDEs like PyCharm or any editor you're comfortable with.\n",
    "\n",
    "Download Cursor from its website and run the installer following standard procedures for your operating system. Once installed, launch Cursor and use File > Open Folder to navigate to your projects/llm-tutorial directory. This sets the course repository as your active project.\n",
    "\n",
    "The interface shows your project files in a sidebar, with the main editor area displaying file contents when you open them. Below, an integrated terminal provides command line access without leaving your editor. This integration streamlines your workflow significantly.\n",
    "\n",
    "Verify you've opened the correct folder by checking that \"llm-tutorial\" appears in block capitals at the top left of the interface, and that you see folders for different weeks in the sidebar.\n",
    "\n",
    "## Installing UV for Package Management\n",
    "\n",
    "Python's extensive ecosystem of third-party packages is one of its greatest strengths. However, managing these packages has historically been challenging. You need to ensure you have the right versions, that they're compatible with each other, and that they don't interfere with other projects on your system.\n",
    "\n",
    "UV represents a modern solution to this problem. Written in Rust for maximum performance, UV can set up a complete Python environment in seconds rather than minutes or hours. It ensures that everyone using the course materials has exactly the same package versions, eliminating compatibility issues.\n",
    "\n",
    "To install UV, visit the UV documentation website. For macOS or Linux, run the curl command provided. For Windows, use the PowerShell command or Windows Package Manager (winget) as documented. The installation completes in seconds.\n",
    "\n",
    "After installation, you may need to open a new terminal window to use UV. Type `uv --version` to confirm it's installed correctly. If you still get an error after opening a new terminal, you might need to restart your computer.\n",
    "\n",
    "Once UV is confirmed working, update it to the latest version:\n",
    "\n",
    "```\n",
    "uv self-update\n",
    "```\n",
    "\n",
    "Now comes the impressive part. Setting up your entire project environment requires just one command:\n",
    "\n",
    "```\n",
    "uv sync\n",
    "```\n",
    "\n",
    "This command reads the project's configuration file, which specifies all required packages and their versions. UV then downloads and installs everything necessary, setting up an isolated environment for this project. What once took up to an hour with older tools now completes in minutes or even seconds. The environment is completely reproducible—anyone running `uv sync` will get exactly the same setup, regardless of their operating system.\n",
    "\n",
    "## Accessing Frontier Models\n",
    "\n",
    "While this course emphasizes local models and self-hosted solutions, accessing frontier models from providers like OpenAI remains valuable for comparison and for tasks requiring maximum capability. This access requires an API key that identifies your account and allows the provider to bill you for usage.\n",
    "\n",
    "Creating an OpenAI API key requires an account on their platform and adding a small amount of credit, typically $5. This prepayment model prevents abuse while keeping costs low. The actual cost per API call is measured in fractions of a cent, so $5 can last through the entire course and beyond.\n",
    "\n",
    "If you prefer to avoid any cost, free alternatives exist. The course will demonstrate how to use these instead, and the fundamental concepts remain identical regardless of which provider you choose.\n",
    "\n",
    "Once you have an API key, it needs to be stored securely in your project through an environment file named `.env`. This file contains key-value pairs that your code can access without hardcoding sensitive information. The setup must be precise—misspelling the filename or variable names will cause failures that can be difficult to diagnose.\n",
    "\n",
    "## Moving Forward\n",
    "\n",
    "Your development environment is now complete. You have Ollama for running local models, Git for version control, an IDE for writing code, UV for package management, and API access to frontier models. You've experienced firsthand what LLMs can do, from basic conversation to practical applications.\n",
    "\n",
    "This foundation supports everything that follows. You'll learn the theory behind how these models work, understand the training processes that instill their capabilities, and master various techniques for adapting models to specific tasks. More importantly, you'll build applications that use these models to solve real problems, developing judgment about when to use which tools and approaches.\n",
    "\n",
    "The field of Large Language Models evolves rapidly, with new capabilities and techniques emerging regularly. By building deep, foundational understanding rather than memorizing specific APIs or tools, you'll be equipped to adapt as the field changes and evaluate new developments critically.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
